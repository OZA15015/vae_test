/home/oza/.pyenv/versions/oza2/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/oza/.pyenv/versions/oza2/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
56000
14000
Epoch: 0 train_loss: 198.6187744140625
Epoch: 0 test_loss: 155.95237731933594
Epoch: 1 train_loss: 142.3037872314453
Epoch: 1 test_loss: 132.30494689941406
Epoch: 2 train_loss: 128.15924072265625
Epoch: 2 test_loss: 123.55435180664062
Epoch: 3 train_loss: 121.52471160888672
Epoch: 3 test_loss: 119.17324829101562
Epoch: 4 train_loss: 117.98990631103516
Epoch: 4 test_loss: 116.71683502197266
Epoch: 5 train_loss: 115.70064544677734
Epoch: 5 test_loss: 114.43480682373047
Epoch: 6 train_loss: 114.07945251464844
Epoch: 6 test_loss: 113.19044494628906
Epoch: 7 train_loss: 112.81876373291016
Epoch: 7 test_loss: 112.45941925048828
Epoch: 8 train_loss: 111.85452270507812
Epoch: 8 test_loss: 111.22980499267578
Epoch: 9 train_loss: 111.0575942993164
Epoch: 9 test_loss: 110.9935302734375
Epoch: 10 train_loss: 110.36075592041016
Epoch: 10 test_loss: 110.24223327636719
Epoch: 11 train_loss: 109.81291961669922
Epoch: 11 test_loss: 109.70391845703125
Epoch: 12 train_loss: 109.25943756103516
Epoch: 12 test_loss: 109.28916931152344
Epoch: 13 train_loss: 108.81861877441406
Epoch: 13 test_loss: 109.45663452148438
Epoch: 14 train_loss: 108.43287658691406
Epoch: 14 test_loss: 108.45963287353516
Epoch: 15 train_loss: 108.03691101074219
Epoch: 15 test_loss: 108.2751693725586
Epoch: 16 train_loss: 107.74787902832031
Epoch: 16 test_loss: 107.7645492553711
Epoch: 17 train_loss: 107.3838119506836
Epoch: 17 test_loss: 107.41492462158203
Epoch: 18 train_loss: 107.15876770019531
Epoch: 18 test_loss: 107.65658569335938
Epoch: 19 train_loss: 106.88239288330078
Epoch: 19 test_loss: 107.07606506347656
Epoch: 20 train_loss: 106.66034698486328
Epoch: 20 test_loss: 106.84686279296875
Epoch: 21 train_loss: 106.46293640136719
Epoch: 21 test_loss: 107.04971313476562
Epoch: 22 train_loss: 106.21817779541016
Epoch: 22 test_loss: 106.6838607788086
Epoch: 23 train_loss: 106.084228515625
Epoch: 23 test_loss: 106.53284454345703
Epoch: 24 train_loss: 105.8602523803711
Epoch: 24 test_loss: 106.4454574584961
Epoch: 25 train_loss: 105.74309539794922
Epoch: 25 test_loss: 106.07133483886719
Epoch: 26 train_loss: 105.55892944335938
Epoch: 26 test_loss: 106.0235824584961
Epoch: 27 train_loss: 105.39002227783203
Epoch: 27 test_loss: 106.01678466796875
Epoch: 28 train_loss: 105.28540802001953
Epoch: 28 test_loss: 105.67627716064453
Epoch: 29 train_loss: 105.12419891357422
Epoch: 29 test_loss: 105.80872344970703
Epoch: 30 train_loss: 105.01011657714844
Epoch: 30 test_loss: 105.66085052490234
Epoch: 31 train_loss: 104.86290740966797
Epoch: 31 test_loss: 105.48979187011719
Epoch: 32 train_loss: 104.77582550048828
Epoch: 32 test_loss: 105.47430419921875
Epoch: 33 train_loss: 104.69035339355469
Epoch: 33 test_loss: 105.67398071289062
Epoch: 34 train_loss: 104.53842163085938
Epoch: 34 test_loss: 105.54241180419922
Epoch: 35 train_loss: 104.44904327392578
Epoch: 35 test_loss: 105.39624786376953
Epoch: 36 train_loss: 104.40526580810547
Epoch: 36 test_loss: 104.87870788574219
Epoch: 37 train_loss: 104.24589538574219
Epoch: 37 test_loss: 105.6305160522461
Epoch: 38 train_loss: 104.18672943115234
Epoch: 38 test_loss: 105.34295654296875
Epoch: 39 train_loss: 104.13478088378906
Epoch: 39 test_loss: 105.02317810058594
Epoch: 40 train_loss: 104.00971984863281
Epoch: 40 test_loss: 105.06747436523438
Epoch: 41 train_loss: 103.94718170166016
Epoch: 41 test_loss: 105.025390625
Epoch: 42 train_loss: 103.85704803466797
Epoch: 42 test_loss: 105.04975128173828
Epoch: 43 train_loss: 103.81082153320312
Epoch: 43 test_loss: 104.44475555419922
Epoch: 44 train_loss: 103.73053741455078
Epoch: 44 test_loss: 104.63318634033203
Epoch: 45 train_loss: 103.6967544555664
Epoch: 45 test_loss: 104.76627349853516
Epoch: 46 train_loss: 103.60149383544922
Epoch: 46 test_loss: 104.76002502441406
Epoch: 47 train_loss: 103.4909896850586
Epoch: 47 test_loss: 104.84701538085938
Epoch: 48 train_loss: 103.43031311035156
Epoch: 48 test_loss: 104.79535675048828
Epoch: 49 train_loss: 103.3688735961914
Epoch: 49 test_loss: 104.45819091796875
